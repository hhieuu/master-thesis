
**** 27.08.2019
Things have done:
- Preparing data, variables
- Trial estimation using LASSO

To work on:
- Adaptive LASSO? for Oracle properties
- How to optimize for lambda? CV?
- Inference
- Estimation periods?
<<<<<<< HEAD
- ADF tests probably?

**** 28.08.2019
To do:
- Figure out how to CV glmnet
- Test for stationarity in all TS?
- Make TS stationary?
- Then the problem of near-collinear/near-singular regression arise?
- Adaptive LASSO needs to be worked on. How to do adaptive LASSO?
- ADF tests probably?

**** 28.08.2019 evening
What I did:
- Ran ADF tests, some are I(1) -> review on regressing with I(1) AR process
      -> what does this have to do with near-singular regression
- Try to do CV, but not concrete and satisfactory. Already found a way to conveniently split TS data ('caret' packages)
      -> Read more on what CV does to find optimal lambda? MSE? PE?
Things to find:
- Is it necessary to use adaptive LASSO wrt its oracle property?
- How about 2-step method for correct coverage of CI? Why does it fail? Does it fail at all?

**** 29.08.2019 evening
What I did:
- Detecting collinearity

More to do:
- Is regression near-singular?
- What to do with near-singularity in context of LASSO?
- Make variables stationary? Read more on regression with unit root (Phillips)

Next up:
- Adaptive LASSO
- 2-step method

**** 16.12.2019
Note:
- Slower-convergence lambda sequences yield better results for DGP2 and DGP3 due to near-singular design.
However, conditions in Lee (2018) still need to be fulfilled.
So n ^ (1 / 2) / log(n) ^ 2 seems to be the best option here for MSPE (still cant beat much of the OLS).
At n ^ (1 / 2) / log(n) ^ 3, alasso beats OLS in term of MSPE, but selection takes a hit.
Scales also have effect on performance as well. Scaling gives better performance, but it means lasso is not
the plain vanilla type anymore, but standardized lasso. In case of alasso, scaling alters the individual penalty
factor. So in most cases, I do not scale (standardize) variables.

To do:
- Run everything again on 2 mentioned, slower, lambda sequences. Compare results.
- Maybe: Add slasso to the mix of feasible estimators.
- Unscale and run again the empirical application.

To be in the thesis:
- Draw TRUE RETURNS vs PREDICTED RETURNS, for several horizon
- Draw ESTIMATED COEFFICIENTS for each variables in one selected case to conclude most selected variables
and the selected range of values.


